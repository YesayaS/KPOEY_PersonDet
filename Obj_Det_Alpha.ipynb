{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Obj Det_Alpha.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb37zJgyUy7k",
        "outputId": "cc10749c-9a7d-4fbb-dca4-67e9a601ecfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os, sys\n",
        "import pathlib\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6ZlblEdU3bj",
        "outputId": "5361e2d4-894b-47f2-f196-7c8b6eda8232",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#!pip install -U --pre tensorflow==\"2.*\"\n",
        "!pip install tf_slim\n",
        "!pip install pycocotools\n",
        "!pip install keyboard\n",
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install Cython"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\r\u001b[K     |█                               | 10kB 9.7MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 2.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (2.0.2)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools) (50.3.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools) (0.29.21)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.18.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools) (1.15.0)\n",
            "Collecting keyboard\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/88/287159903c5b3fc6d47b651c7ab65a54dcf9c9916de546188a7f62870d6d/keyboard-0.13.5-py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.0MB/s \n",
            "\u001b[?25hInstalling collected packages: keyboard\n",
            "Successfully installed keyboard-0.13.5\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "python-tk is already the newest version (2.7.17-1~18.04).\n",
            "The following additional packages will be installed:\n",
            "  python-bs4 python-chardet python-html5lib python-olefile\n",
            "  python-pkg-resources python-six python-webencodings\n",
            "Suggested packages:\n",
            "  python-genshi python-lxml-dbg python-lxml-doc python-pil-doc python-pil-dbg\n",
            "  python-setuptools\n",
            "The following NEW packages will be installed:\n",
            "  python-bs4 python-chardet python-html5lib python-lxml python-olefile\n",
            "  python-pil python-pkg-resources python-six python-webencodings\n",
            "0 upgraded, 9 newly installed, 0 to remove and 21 not upgraded.\n",
            "Need to get 1,791 kB of archives.\n",
            "After this operation, 7,807 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-bs4 all 4.6.0-1 [67.9 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-chardet all 3.0.4-1 [80.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-webencodings all 0.5-2 [10.3 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-html5lib all 0.999999999-1 [83.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-lxml amd64 4.2.1-1ubuntu0.1 [1,075 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-olefile all 0.45.1-1 [33.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-pil amd64 5.1.0-1ubuntu0.3 [301 kB]\n",
            "Fetched 1,791 kB in 1s (1,965 kB/s)\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 144611 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.3) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.3) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.21)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BujGJ6ynVHjS"
      },
      "source": [
        "# CLONE DE GIT\n",
        "# try:\n",
        "#   if \"drive/My\\ Drive/models\" in pathlib.Path.cwd().parts:\n",
        "#     while \"drive/My\\ Drive/models\" in pathlib.Path.cwd().parts:\n",
        "#       os.chdir('/content/drive/My Drive')\n",
        "#   elif not pathlib.Path('drive/My\\ Drive/models').exists():\n",
        "#     os.chdir('/content/drive/My Drive')\n",
        "#     !git clone --depth 1 https://github.com/tensorflow/models\n",
        "# except:\n",
        "#   None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0GZaooNVPZ9",
        "outputId": "cd7012e1-e64b-4068-817e-44fb80200158",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# compile proto files\n",
        "# make sure you are in BASE_DIR/research/ (see cell below)\n",
        "%cd /content/drive/My Drive/models/research/\n",
        "# !protoc object_detection/protos/*.proto --python_out=.\n",
        "# !cp object_detection/packages/tf2/setup.py .\n",
        "# !python -m pip install ."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-XifOKSVRUI",
        "outputId": "5a822e2c-b65d-4050-c96e-1b72e0d2372b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(os.getcwd())\n",
        "os.chdir(\"/content/drive/My Drive/models/research/object_detection\")\n",
        "print(os.getcwd())\n",
        "try:\n",
        "  DATA_DIR = os.path.join(os.getcwd(), 'data')\n",
        "  MODELS_DIR = os.path.join(DATA_DIR, 'models')\n",
        "  for dir in [DATA_DIR, MODELS_DIR]:\n",
        "    if not os.path.exists(dir):\n",
        "      os.mkdir(dir)\n",
        "except:\n",
        "  print('error')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/models/research\n",
            "/content/drive/My Drive/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9tM2U5oVTGI"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "# os.chdir('/research')\n",
        "\n",
        "# Download and extract model\n",
        "MODEL_DATE = '20200711'\n",
        "#'efficientdet_d2_coco17_tpu-32' #my primary model\n",
        "#'centernet_resnet101_v1_fpn_512x512_coco17_tpu-8' #secondary model (worst)\n",
        "#'efficientdet_d3_coco17_tpu-32' #third model (should be finest)\n",
        "MODEL_NAME = 'efficientdet_d2_coco17_tpu-32'\n",
        "MODEL_TAR_FILENAME = MODEL_NAME + '.tar.gz'\n",
        "MODELS_DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/tf2/'\n",
        "MODEL_DOWNLOAD_LINK = MODELS_DOWNLOAD_BASE + MODEL_DATE + '/' + MODEL_TAR_FILENAME\n",
        "PATH_TO_MODEL_TAR = os.path.join(MODELS_DIR, MODEL_TAR_FILENAME)\n",
        "PATH_TO_CKPT = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'checkpoint/'))\n",
        "PATH_TO_CFG = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'pipeline.config'))\n",
        "if not os.path.exists(PATH_TO_CKPT):\n",
        "  print('Downloading model. This may take a while... ', end='')\n",
        "  urllib.request.urlretrieve(MODEL_DOWNLOAD_LINK, PATH_TO_MODEL_TAR)\n",
        "  tar_file = tarfile.open(PATH_TO_MODEL_TAR)\n",
        "  tar_file.extractall(MODELS_DIR)\n",
        "  tar_file.close()\n",
        "  os.remove(PATH_TO_MODEL_TAR)\n",
        "  print('Done')\n",
        "\n",
        "# Download labels file\n",
        "LABEL_FILENAME = 'mscoco_label_map.pbtxt'\n",
        "LABELS_DOWNLOAD_BASE = \\\n",
        "    'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/'\n",
        "PATH_TO_LABELS = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, LABEL_FILENAME))\n",
        "if not os.path.exists(PATH_TO_LABELS):\n",
        "  print('Downloading label file... ', end='')\n",
        "  urllib.request.urlretrieve(LABELS_DOWNLOAD_BASE + LABEL_FILENAME, PATH_TO_LABELS)\n",
        "  print('Done')# %%bash"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBXeXmJjVWzV",
        "outputId": "38d276f1-ef58-4a15-f49d-1c8443279f23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(os.getcwd())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr5OHBZFVa-a",
        "outputId": "5a947941-63a1-466b-f45a-28b31a19445a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(PATH_TO_CFG)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/models/research/object_detection/data/models/efficientdet_d2_coco17_tpu-32/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS30S2jAVb6p"
      },
      "source": [
        "os.chdir('/content/drive/My Drive/models/research')\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "os.chdir('/content/drive/My Drive/models')\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
        "\n",
        "# Enable GPU dynamic memory allocation\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)\n",
        "model_config = configs['model']\n",
        "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(PATH_TO_CKPT, 'ckpt-0')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    \"\"\"Detect objects in image.\"\"\"\n",
        "\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "\n",
        "    return detections, prediction_dict, tf.reshape(shapes, [-1])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SW3GzobVc_E"
      },
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
        "                                                                    use_display_name=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jhOwPuDVeVS",
        "outputId": "634e136f-2df7-4748-c1da-6f35fa4816c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(category_index)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: {'id': 1, 'name': 'person'}, 2: {'id': 2, 'name': 'bicycle'}, 3: {'id': 3, 'name': 'car'}, 4: {'id': 4, 'name': 'motorcycle'}, 5: {'id': 5, 'name': 'airplane'}, 6: {'id': 6, 'name': 'bus'}, 7: {'id': 7, 'name': 'train'}, 8: {'id': 8, 'name': 'truck'}, 9: {'id': 9, 'name': 'boat'}, 10: {'id': 10, 'name': 'traffic light'}, 11: {'id': 11, 'name': 'fire hydrant'}, 13: {'id': 13, 'name': 'stop sign'}, 14: {'id': 14, 'name': 'parking meter'}, 15: {'id': 15, 'name': 'bench'}, 16: {'id': 16, 'name': 'bird'}, 17: {'id': 17, 'name': 'cat'}, 18: {'id': 18, 'name': 'dog'}, 19: {'id': 19, 'name': 'horse'}, 20: {'id': 20, 'name': 'sheep'}, 21: {'id': 21, 'name': 'cow'}, 22: {'id': 22, 'name': 'elephant'}, 23: {'id': 23, 'name': 'bear'}, 24: {'id': 24, 'name': 'zebra'}, 25: {'id': 25, 'name': 'giraffe'}, 27: {'id': 27, 'name': 'backpack'}, 28: {'id': 28, 'name': 'umbrella'}, 31: {'id': 31, 'name': 'handbag'}, 32: {'id': 32, 'name': 'tie'}, 33: {'id': 33, 'name': 'suitcase'}, 34: {'id': 34, 'name': 'frisbee'}, 35: {'id': 35, 'name': 'skis'}, 36: {'id': 36, 'name': 'snowboard'}, 37: {'id': 37, 'name': 'sports ball'}, 38: {'id': 38, 'name': 'kite'}, 39: {'id': 39, 'name': 'baseball bat'}, 40: {'id': 40, 'name': 'baseball glove'}, 41: {'id': 41, 'name': 'skateboard'}, 42: {'id': 42, 'name': 'surfboard'}, 43: {'id': 43, 'name': 'tennis racket'}, 44: {'id': 44, 'name': 'bottle'}, 46: {'id': 46, 'name': 'wine glass'}, 47: {'id': 47, 'name': 'cup'}, 48: {'id': 48, 'name': 'fork'}, 49: {'id': 49, 'name': 'knife'}, 50: {'id': 50, 'name': 'spoon'}, 51: {'id': 51, 'name': 'bowl'}, 52: {'id': 52, 'name': 'banana'}, 53: {'id': 53, 'name': 'apple'}, 54: {'id': 54, 'name': 'sandwich'}, 55: {'id': 55, 'name': 'orange'}, 56: {'id': 56, 'name': 'broccoli'}, 57: {'id': 57, 'name': 'carrot'}, 58: {'id': 58, 'name': 'hot dog'}, 59: {'id': 59, 'name': 'pizza'}, 60: {'id': 60, 'name': 'donut'}, 61: {'id': 61, 'name': 'cake'}, 62: {'id': 62, 'name': 'chair'}, 63: {'id': 63, 'name': 'couch'}, 64: {'id': 64, 'name': 'potted plant'}, 65: {'id': 65, 'name': 'bed'}, 67: {'id': 67, 'name': 'dining table'}, 70: {'id': 70, 'name': 'toilet'}, 72: {'id': 72, 'name': 'tv'}, 73: {'id': 73, 'name': 'laptop'}, 74: {'id': 74, 'name': 'mouse'}, 75: {'id': 75, 'name': 'remote'}, 76: {'id': 76, 'name': 'keyboard'}, 77: {'id': 77, 'name': 'cell phone'}, 78: {'id': 78, 'name': 'microwave'}, 79: {'id': 79, 'name': 'oven'}, 80: {'id': 80, 'name': 'toaster'}, 81: {'id': 81, 'name': 'sink'}, 82: {'id': 82, 'name': 'refrigerator'}, 84: {'id': 84, 'name': 'book'}, 85: {'id': 85, 'name': 'clock'}, 86: {'id': 86, 'name': 'vase'}, 87: {'id': 87, 'name': 'scissors'}, 88: {'id': 88, 'name': 'teddy bear'}, 89: {'id': 89, 'name': 'hair drier'}, 90: {'id': 90, 'name': 'toothbrush'}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss9LviHCVfhQ"
      },
      "source": [
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3cvJL9jxOJH"
      },
      "source": [
        "# A Python3 program to find if 2 given line segments intersect or not \n",
        "  \n",
        "class Point: \n",
        "    def __init__(self, x, y): \n",
        "        self.x = x \n",
        "        self.y = y \n",
        "  \n",
        "# Given three colinear points p, q, r, the function checks if  \n",
        "# point q lies on line segment 'pr'  \n",
        "def onSegment(p, q, r): \n",
        "    if ( (q.x <= max(p.x, r.x)) and (q.x >= min(p.x, r.x)) and \n",
        "           (q.y <= max(p.y, r.y)) and (q.y >= min(p.y, r.y))): \n",
        "        return True\n",
        "    return False\n",
        "  \n",
        "def orientation(p, q, r): \n",
        "    # to find the orientation of an ordered triplet (p,q,r) \n",
        "    # function returns the following values: \n",
        "    # 0 : Colinear points \n",
        "    # 1 : Clockwise points \n",
        "    # 2 : Counterclockwise \n",
        "      \n",
        "    # See https://www.geeksforgeeks.org/orientation-3-ordered-points/amp/  \n",
        "    # for details of below formula.  \n",
        "      \n",
        "    val = (float(q.y - p.y) * (r.x - q.x)) - (float(q.x - p.x) * (r.y - q.y)) \n",
        "    if (val > 0): \n",
        "          \n",
        "        # Clockwise orientation \n",
        "        return 1\n",
        "    elif (val < 0): \n",
        "          \n",
        "        # Counterclockwise orientation \n",
        "        return 2\n",
        "    else: \n",
        "          \n",
        "        # Colinear orientation \n",
        "        return 0\n",
        "  \n",
        "# The main function that returns true if  \n",
        "# the line segment 'p1q1' and 'p2q2' intersect. \n",
        "def doIntersect(p1,q1,p2,q2): \n",
        "      \n",
        "    # Find the 4 orientations required for  \n",
        "    # the general and special cases \n",
        "    o1 = orientation(p1, q1, p2) \n",
        "    o2 = orientation(p1, q1, q2) \n",
        "    o3 = orientation(p2, q2, p1) \n",
        "    o4 = orientation(p2, q2, q1) \n",
        "  \n",
        "    # General case \n",
        "    if ((o1 != o2) and (o3 != o4)): \n",
        "        return True\n",
        "  \n",
        "    # Special Cases \n",
        "  \n",
        "    # p1 , q1 and p2 are colinear and p2 lies on segment p1q1 \n",
        "    if ((o1 == 0) and onSegment(p1, p2, q1)): \n",
        "        return True\n",
        "  \n",
        "    # p1 , q1 and q2 are colinear and q2 lies on segment p1q1 \n",
        "    if ((o2 == 0) and onSegment(p1, q2, q1)): \n",
        "        return True\n",
        "  \n",
        "    # p2 , q2 and p1 are colinear and p1 lies on segment p2q2 \n",
        "    if ((o3 == 0) and onSegment(p2, p1, q2)): \n",
        "        return True\n",
        "  \n",
        "    # p2 , q2 and q1 are colinear and q1 lies on segment p2q2 \n",
        "    if ((o4 == 0) and onSegment(p2, q1, q2)): \n",
        "        return True\n",
        "  \n",
        "    # If none of the cases \n",
        "    return False"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_K8b7xVXmta"
      },
      "source": [
        "def draw_centroid(frame, centroid):\n",
        "  red = (0, 0, 255)\n",
        "  value = tuple(centroid)\n",
        "  cv2.circle(frame, value, 1, red, 10)\n",
        "\n",
        "def draw_text(frame, centroid, id):\n",
        "  centroid = tuple(centroid)\n",
        "  green = (0, 255, 0)\n",
        "  font = cv2.FONT_HERSHEY_PLAIN\n",
        "  cv2.putText(frame, \"Person #\" + str(id), centroid, font, 2, green, 2, cv2.LINE_AA)\n",
        "\n",
        "def draw_counter_text(frame, count):\n",
        "  position = (100,100)\n",
        "  green = (0, 0, 255)\n",
        "  font = cv2.FONT_HERSHEY_PLAIN\n",
        "  cv2.putText(frame, \"Counter :\" + str(count), position, font, 3, green, 3, cv2.LINE_AA)\n",
        "\n",
        "def draw_in_out_text(frame, count_in, count_out):\n",
        "  position_in = (100,90)\n",
        "  position_out = (100,130)\n",
        "  green = (0, 0, 255)\n",
        "  font = cv2.FONT_HERSHEY_PLAIN\n",
        "  text_in = \"In : \" + str(count_in)\n",
        "  text_out = \"Out : \" + str(count_out)\n",
        "  cv2.putText(frame, text_in, position_in, font, 3, green, 3, cv2.LINE_AA)\n",
        "  cv2.putText(frame, text_out, position_out, font, 3, green, 3, cv2.LINE_AA)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7qLV6khV9Yl"
      },
      "source": [
        "# The following has been modified to fit TF2's vis util box normalized bounding box\n",
        "# import the necessary packages\n",
        "from scipy.spatial import distance as dist\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "\n",
        "class CentroidTracker():\n",
        "\tdef __init__(self, frame_shape, maxDisappeared=50, dualCounter=True):\n",
        "\t\t# initialize the next unique object ID along with two ordered\n",
        "\t\t# dictionaries used to keep track of mapping a given object\n",
        "\t\t# ID to its centroid and number of consecutive frames it has\n",
        "\t\t# been marked as \"disappeared\", respectively\n",
        "\t\tself.nextObjectID = 0\n",
        "\t\tself.objects = OrderedDict()\n",
        "\t\tself.disappeared = OrderedDict()\n",
        "\t\t# Height, width and color channel of the frame\n",
        "\t\tself.height, self.width, self.channel = frame_shape\n",
        "\t\tself.count_in = 0  # no. of visitors entering the building\n",
        "\t\tself.count_out = 0 # no. of visitors exiting the building\n",
        "\n",
        "\t\t# store the number of maximum consecutive frames a given\n",
        "\t\t# object is allowed to be marked as \"disappeared\" until we\n",
        "\t\t# need to deregister the object from tracking\n",
        "\t\tself.maxDisappeared = maxDisappeared\n",
        "\n",
        "\t\t# Display people enterring and exitting separately if set to true\n",
        "\t\tself.dualCounter = dualCounter\n",
        "\n",
        "\tdef register(self, centroid):\n",
        "\t\t# when registering an object we use the next available object\n",
        "\t\t# ID to store the centroid\n",
        "\t\tself.objects[self.nextObjectID] = centroid\n",
        "\t\tself.disappeared[self.nextObjectID] = 0\n",
        "\t\tself.nextObjectID += 1\n",
        "\n",
        "\tdef deregister(self, objectID):\n",
        "\t\t# to deregister an object ID we delete the object ID from\n",
        "\t\t# both of our respective dictionaries\n",
        "\t\tdel self.objects[objectID]\n",
        "\t\tdel self.disappeared[objectID]\n",
        "\n",
        "\tdef update(self, frame, rects, count=False, ROI_start_point=None, ROI_end_point=None):\n",
        "\n",
        "\t\t# If counter displays people enterring and exitting the building \n",
        "\t\t# separately\n",
        "\t\tif self.dualCounter:\n",
        "\t\t\tdraw_in_out_text(frame, self.count_in, self.count_out) # draw in/out counter\n",
        "\t\t# else if the counter only displays the number of people in the building\n",
        "\t\telse:\n",
        "\t\t\tcounter = self.count_in - self.count_out\n",
        "\t\t\tdraw_counter_text(frame,counter)  # draw a counter\n",
        "\n",
        "\t\t# check to see if the list of input bounding box rectangles\n",
        "\t\t# is empty\n",
        "\t\tif len(rects) == 0:\n",
        "\t\t\t# loop over any existing tracked objects and mark them\n",
        "\t\t\t# as disappeared\n",
        "\t\t\tfor objectID in list(self.disappeared.keys()):\n",
        "\t\t\t\tself.disappeared[objectID] += 1\n",
        "\n",
        "\t\t\t\t# if we have reached a maximum number of consecutive\n",
        "\t\t\t\t# frames where a given object has been marked as\n",
        "\t\t\t\t# missing, deregister it\n",
        "\t\t\t\tif self.disappeared[objectID] > self.maxDisappeared:\n",
        "\t\t\t\t\tself.deregister(objectID)\n",
        "\n",
        "\t\t\t# return early as there are no centroids or tracking info\n",
        "\t\t\t# to update\n",
        "\t\t\treturn self.objects\n",
        "\n",
        "\t\t# initialize an array of input centroids for the current frame\n",
        "\t\tinputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
        "\n",
        "\t\t# loop over the bounding box rectangles\n",
        "\t\tfor (i, (endY, endX, startY, startX)) in enumerate(rects):\n",
        "\t\t\t# denormalize the bounding box coordinate\n",
        "\t\t\td_minX = startX * self.height\n",
        "\t\t\td_maxX = endX * self.height\n",
        "\t\t\td_minY = startY * self.width\n",
        "\t\t\td_maxY = endY * self.width\n",
        "\t\t\t# use the bounding box coordinates to derive the centroid\n",
        "\t\t\tcX = int((d_minX + d_maxX) / 2.0)\n",
        "\t\t\tcY = int((d_minY + d_maxY) / 2.0)\n",
        "\t\t\tinputCentroids[i] = (cX, cY)\n",
        "\n",
        "\t\t# if we are currently not tracking any objects take the input\n",
        "\t\t# centroids and register each of them\n",
        "\t\tif len(self.objects) == 0:\n",
        "\t\t\tfor i in range(0, len(inputCentroids)):\n",
        "\t\t\t\tself.register(inputCentroids[i])\n",
        "\t\t\t\tdraw_centroid(frame, inputCentroids[i])  # draw centroid if new person is detected AND Tracker is not tracking\n",
        "\t\t\t\tdraw_text(frame, inputCentroids[i], self.nextObjectID-1)\n",
        "\n",
        "\t\t# otherwise, are are currently tracking objects so we need to\n",
        "\t\t# try to match the input centroids to existing object\n",
        "\t\t# centroids\n",
        "\t\telse:\n",
        "\t\t\t# grab the set of object IDs and corresponding centroids\n",
        "\t\t\tobjectIDs = list(self.objects.keys())\n",
        "\t\t\tobjectCentroids = list(self.objects.values())\n",
        "\n",
        "\t\t\t# compute the distance between each pair of object\n",
        "\t\t\t# centroids and input centroids, respectively -- our\n",
        "\t\t\t# goal will be to match an input centroid to an existing\n",
        "\t\t\t# object centroid\n",
        "\t\t\tD = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
        "\n",
        "\t\t\t# in order to perform this matching we must (1) find the\n",
        "\t\t\t# smallest value in each row and then (2) sort the row\n",
        "\t\t\t# indexes based on their minimum values so that the row\n",
        "\t\t\t# with the smallest value as at the *front* of the index\n",
        "\t\t\t# list\n",
        "\t\t\trows = D.min(axis=1).argsort()\n",
        "\n",
        "\t\t\t# next, we perform a similar process on the columns by\n",
        "\t\t\t# finding the smallest value in each column and then\n",
        "\t\t\t# sorting using the previously computed row index list\n",
        "\t\t\tcols = D.argmin(axis=1)[rows]\n",
        "\n",
        "\t\t\t# in order to determine if we need to update, register,\n",
        "\t\t\t# or deregister an object we need to keep track of which\n",
        "\t\t\t# of the rows and column indexes we have already examined\n",
        "\t\t\tusedRows = set()\n",
        "\t\t\tusedCols = set()\n",
        "\n",
        "\t\t\t# loop over the combination of the (row, column) index\n",
        "\t\t\t# tuples\n",
        "\t\t\tfor (row, col) in zip(rows, cols):\n",
        "\t\t\t\t# if we have already examined either the row or\n",
        "\t\t\t\t# column value before, ignore it\n",
        "\t\t\t\t# val\n",
        "\t\t\t\tif row in usedRows or col in usedCols:\n",
        "\t\t\t\t\tcontinue\n",
        "\n",
        "\t\t\t\t# otherwise, grab the object ID for the current row,\n",
        "\t\t\t\t# set its new centroid, and reset the disappeared\n",
        "\t\t\t\t# counter\n",
        "\t\t\t\tobjectID = objectIDs[row]\n",
        "\n",
        "\t\t\t\t# Check to see first if that object has crossed the ROI\n",
        "\t\t\t\tif count:  # counting only starts if it's enabled\n",
        "\t\t\t\t\tif (self.objects[objectID]).all():\n",
        "\t\t\t\t\t\tbeforeMove = Point(int(self.objects[objectID][0]), int(self.objects[objectID][1]))\n",
        "\t\t\t\t\t\tafterMove = Point(int(inputCentroids[col][0]), int(inputCentroids[col][1]))\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\t\tif doIntersect(ROI_start_point, ROI_end_point, beforeMove, afterMove):\n",
        "\t\t\t\t\t\t\t# If the current centroid is below the ROI, counter goes up\n",
        "\t\t\t\t\t\t\t# meaning an object has entered the building\n",
        "\t\t\t\t\t\t\tif afterMove.y > ROI_start_point.y:  # if y is higher means it's below in the actual frame\n",
        "\t\t\t\t\t\t\t\tself.count_in += 1\n",
        "\t\t\t\t\t\t\telse:\n",
        "\t\t\t\t\t\t\t\tself.count_out -= 1  # if it's the opposite means an object has exited the building\n",
        "\n",
        "\t\t\t\tself.objects[objectID] = inputCentroids[col]\n",
        "\t\t\t\tself.disappeared[objectID] = 0\n",
        "\t\t\t\tdraw_centroid(frame, inputCentroids[col])  # draw centroid when a person moved\n",
        "\t\t\t\tdraw_text(frame, inputCentroids[col], objectID)\n",
        "\n",
        "\t\t\t\t# indicate that we have examined each of the row and\n",
        "\t\t\t\t# column indexes, respectively\n",
        "\t\t\t\tusedRows.add(row)\n",
        "\t\t\t\tusedCols.add(col)\n",
        "\n",
        "\t\t\t# compute both the row and column index we have NOT yet\n",
        "\t\t\t# examined\n",
        "\t\t\tunusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
        "\t\t\tunusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
        "\n",
        "\t\t\t# in the event that the number of object centroids is\n",
        "\t\t\t# equal or greater than the number of input centroids\n",
        "\t\t\t# we need to check and see if some of these objects have\n",
        "\t\t\t# potentially disappeared\n",
        "\t\t\tif D.shape[0] >= D.shape[1]:\n",
        "\t\t\t\t# loop over the unused row indexes\n",
        "\t\t\t\tfor row in unusedRows:\n",
        "\t\t\t\t\t# grab the object ID for the corresponding row\n",
        "\t\t\t\t\t# index and increment the disappeared counter\n",
        "\t\t\t\t\tobjectID = objectIDs[row]\n",
        "\t\t\t\t\tself.disappeared[objectID] += 1\n",
        "\n",
        "\t\t\t\t\t# check to see if the number of consecutive\n",
        "\t\t\t\t\t# frames the object has been marked \"disappeared\"\n",
        "\t\t\t\t\t# for warrants deregistering the object\n",
        "\t\t\t\t\tif self.disappeared[objectID] > self.maxDisappeared:\n",
        "\t\t\t\t\t\tself.deregister(objectID)\n",
        "\n",
        "\t\t\t# otherwise, if the number of input centroids is greater\n",
        "\t\t\t# than the number of existing object centroids we need to\n",
        "\t\t\t# register each new input centroid as a trackable object\n",
        "\t\t\telse:\n",
        "\t\t\t\tfor col in unusedCols:\n",
        "\t\t\t\t\tself.register(inputCentroids[col])\n",
        "\t\t\t\t\tdraw_centroid(frame, inputCentroids[col])  # draw a centroid when a new person is detected\n",
        "\t\t\t\t\tdraw_text(frame, inputCentroids[col], self.nextObjectID-1)\n",
        "\n",
        "\t\t# return the set of trackable objects\n",
        "\t\treturn self.objects"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaFHjoofWEdH"
      },
      "source": [
        "def confidence_pruning(boxes, scores, min_threshold=0.3):\n",
        "  indices = np.squeeze(np.argwhere(scores >= min_threshold))\n",
        "  boxes_pruned = boxes[[indices]]\n",
        "  if boxes_pruned.ndim < 2:\n",
        "    boxes_pruned = np.expand_dims(boxes_pruned, axis=0)\n",
        "  return boxes_pruned"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tzl6pFtNWGwg"
      },
      "source": [
        "import time\n",
        "from datetime import date"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoEyW_x9VgjL",
        "outputId": "aa9661f4-1384-4808-bb0f-131d2402b689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "today = str(date.today())\n",
        "\n",
        "thresh = 0.35 #threshold for filtering person\n",
        "\n",
        "### INPUT & OUTPUT VIDEO FILES ###\n",
        "#25 AGST 20 1145 1200.avi #my main vid\n",
        "#1 sept 2020 1100 1130.avi #second vid\n",
        "VIDEO_NAME = '1 sept _ kopi oey -12frame.mp4'\n",
        "VIDEODIR = '/content/drive/My Drive/objDet/vid/' + VIDEO_NAME\n",
        "OUTDIR = '/content/drive/My Drive/objDet/outvid/' + 'TEST' + today + 'short_thresh:'+str(thresh)  + MODEL_NAME + '__' + VIDEO_NAME\n",
        "\n",
        "### SETTING UP CV2 & VIDEO ###\n",
        "cap = cv2.VideoCapture(VIDEODIR) #Getting video for cv2\n",
        "#default centerDet thresh = 0.55\n",
        "#centerDet d2 = 0.45 1st run\n",
        "#centerDet d2 = 0.4  2nd run\n",
        "#default centerNet thresh = 0.3 ~ 0.35\n",
        "\n",
        "### VIDEO TECHNICAL ###\n",
        "ret, image_np = cap.read()\n",
        "fshape = image_np.shape\n",
        "fheight = fshape[0]\n",
        "fwidth = fshape[1]\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "print(\"fps :\",fps)\n",
        "res = (fwidth , fheight)\n",
        "print(\"res :\",res)\n",
        "#.mp4 format : *'MP4V' ; .avi : *'XVID'\n",
        "out = cv2.VideoWriter(OUTDIR,cv2.VideoWriter_fourcc(*'MP4V'), fps, res)\n",
        "\n",
        "### GETTING CENTROID IF ANY DETECTION ###\n",
        "Tracker = CentroidTracker([fwidth,fheight,3], maxDisappeared=30)\n",
        "\n",
        "### LINE INTERSECT FOR COUNTING\n",
        "start_point = (0, int(fheight*0.65))\n",
        "end_point = (int(fwidth), int(fheight*0.65))\n",
        "color = (255,0,0)\n",
        "thickness = 5\n",
        "ROI_start_point = Point(start_point[0], start_point[1])\n",
        "ROI_end_point = Point(end_point[0], end_point[1])\n",
        "\n",
        "### SETTING UP WHEN to START & STOP, SHOWING DURATION ###   <---------------------------------###########################\n",
        "startDetection = 3 * 60 + 9 #when to start detect\n",
        "length = 1 * 2 #in second(s)  #Length how long to detect\n",
        "\n",
        "l_startDetection = startDetection * fps #how many frames to skip detect\n",
        "cap.set(cv2.CAP_PROP_POS_FRAMES, l_startDetection) #skip frame\n",
        "l_fps = length * fps #how many frames to detect\n",
        "i = 0 #initiate first frame\n",
        "\n",
        "### IT'S ALL BEGIN ###\n",
        "if not (startDetection == 0):\n",
        "  print('{} s are skipped!'.format(startDetection))\n",
        "print('Ready to process!')\n",
        "\n",
        "label_id_offset = 1\n",
        "\n",
        "startTime = time.time() #how long it takes to process desired length video\n",
        "\n",
        "while (i < l_fps): #start to detect\n",
        "  # Read frame from video\n",
        "  ret, image_np = cap.read()\n",
        "\n",
        "  if not ret:\n",
        "    break\n",
        "\n",
        "  #Draw a line for counting\n",
        "  cv2.line(image_np, start_point, end_point, color, thickness)\n",
        "\n",
        "  input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "  detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
        "\n",
        "  indices = np.squeeze(np.argwhere((detections['detection_classes'][0].numpy() + label_id_offset).astype(int) == 1))\n",
        "  boxes = detections['detection_boxes'][0].numpy()\n",
        "  boxes = boxes[[indices]]\n",
        "  classes = (detections['detection_classes'][0] + label_id_offset).numpy()\n",
        "  classes = classes[[indices]].astype(int)\n",
        "  scores = detections['detection_scores'][0].numpy()\n",
        "  scores = scores[[indices]]\n",
        "  boxes = confidence_pruning(boxes, scores, thresh)\n",
        "\n",
        "  People = Tracker.update(image_np, boxes, count=True, ROI_start_point=ROI_start_point, ROI_end_point=ROI_end_point)\n",
        "\n",
        "  print(\"\\r progress: {} s / {} s\".format(str(int(((i+1)/fps))),length), end =\" \")\n",
        "\n",
        "  # Display output\n",
        "  #nFrame = cv2.resize(image_np_with_detections, (800, 600))\n",
        "  #cv2.imshow('object detection', nFrame)\n",
        "  \n",
        "  # write the frame\n",
        "  out.write(image_np)\n",
        "\n",
        "  i = i+1\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "doneTime = time.time()-startTime\n",
        "print(\"\")\n",
        "print(\"DONE!\")\n",
        "print(\"Saved as :\",OUTDIR)\n",
        "print(\"Finish in : {} (s)\".format(float(doneTime)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fps : 12\n",
            "res : (1920, 1080)\n",
            "189 s are skipped!\n",
            "Ready to process!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:77: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:79: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " progress: 1 s / 2 s 0\n",
            " progress: 1 s / 2 s 0\n",
            " progress: 1 s / 2 s 0\n",
            " progress: 1 s / 2 s 0\n",
            " progress: 1 s / 2 s 0\n",
            " progress: 1 s / 2 s 0\n",
            " progress: 1 s / 2 s 0\n",
            " progress: 1 s / 2 s 0\n",
            " progress: 1 s / 2 s 0\n",
            " progress: 1 s / 2 s 0\n",
            " progress: 1 s / 2 s 0\n",
            " progress: 1 s / 2 s 0\n",
            " progress: 2 s / 2 s \n",
            "DONE!\n",
            "Saved as : /content/drive/My Drive/objDet/outvid/TEST2020-10-18short_thresh:0.35efficientdet_d2_coco17_tpu-32__1 sept _ kopi oey -12frame.mp4\n",
            "Finish in : 9.952859878540039 (s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15LXAgqBgZR4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}